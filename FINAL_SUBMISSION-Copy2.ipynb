{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string, random, pickle, nltk, scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import FreqDist\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(set(stopwords.words('english')))\n",
    "text_train = pd.read_csv(r\"datasets/review_text_train.csv\", index_col = False, delimiter = ',', header=0)\n",
    "meta_train = pd.read_csv(r\"datasets/review_meta_train.csv\", index_col = False, delimiter = ',', header=0)\n",
    "text_test = pd.read_csv(r\"datasets/review_text_test.csv\", index_col = False, delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\"N\": wordnet.NOUN,\"V\": wordnet.VERB,\"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "all_reviews1 = []\n",
    "all_words = []\n",
    "allowed_p_o_s = [\"J\",\"V\",\"R\"]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "l=0\n",
    "\n",
    "for i in range(0,text_train.shape[0]):\n",
    "    text = text_train.at[i,'review']\n",
    "    rating = meta_train.at[i,'rating']\n",
    "    new_text = ''\n",
    "    \n",
    "    cleaned_text = re.sub(r'[^(a-zA-Z)\\s]',' ', text)\n",
    "    tokenized_text = word_tokenize(cleaned_text)\n",
    "    \n",
    "    text_w_o_stop = [word for word in tokenized_text if not word in stop_words]\n",
    "\n",
    "    for token, tag in nltk.pos_tag(text_w_o_stop):\n",
    "        p_o_s = get_wordnet_pos(token)\n",
    "        token = lemmatizer.lemmatize(token, p_o_s)\n",
    "        if tag[0] in allowed_p_o_s:\n",
    "            new_text+=token.lower()\n",
    "            new_text+=' '\n",
    "    tup = (new_text,rating)\n",
    "    all_reviews1.append(tup)\n",
    "    if l%1000==0:\n",
    "        print(l)\n",
    "    l+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excellent fantastic well know know make comfortable great cheese great great salad decor new old minor right ',\n",
       "  5),\n",
       " ('kill yet difficult get self aspect go early last team yap sit right outside bad get perfect miserable want atmosphere hold go loud want hit ',\n",
       "  1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "random.shuffle(all_reviews1)\n",
    "\n",
    "all_reviews = [a[0] for a in all_reviews1]\n",
    "all_ratings = [a[1] for a in all_reviews1]\n",
    "\n",
    "lim = int(len(all_reviews)*.8)\n",
    "my_reviews_train_clean = all_reviews[:lim]\n",
    "my_reviews_test_clean = all_reviews[lim:]\n",
    "my_target_train = all_ratings[:lim]\n",
    "my_target_test = all_ratings[lim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\n"
     ]
    }
   ],
   "source": [
    "print('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "my_vectorizer.fit(my_reviews_train_clean)\n",
    "X_all = my_vectorizer.transform(all_reviews)\n",
    "my_test_reviews = list(text_test['review'])\n",
    "X_test_all = my_vectorizer.transform(my_test_reviews)\n",
    "X = my_vectorizer.transform(my_reviews_train_clean)\n",
    "X_test = my_vectorizer.transform(my_reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, given_features):\n",
    "        classifier_votes = []\n",
    "        for c in self._classifiers:\n",
    "            vote = int(c.predict(given_features))\n",
    "            classifier_votes.append(vote)\n",
    "        return Counter(classifier_votes).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB_clf = MultinomialNB(alpha=0.5, fit_prior=False)\n",
    "MNB_clf.fit(X, my_target_train)\n",
    "\n",
    "BNB_clf = BernoulliNB(alpha = 0.001)\n",
    "BNB_clf.fit(X, my_target_train)\n",
    "\n",
    "LogReg_clf = LogisticRegression(C=0.5)\n",
    "LogReg_clf.fit(X, my_target_train)\n",
    "\n",
    "SGD_clf = SGDClassifier(loss='perceptron')\n",
    "SGD_clf.fit(X, my_target_train)\n",
    "\n",
    "SVC_clf = LinearSVC(C=0.05)\n",
    "SVC_clf.fit(X, my_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for MultinomialNB model = 0.7686141788386177\n",
      "(array([0.65492958, 0.62357414, 0.79649797]), array([0.20993228, 0.37992278, 0.9623323 ]), array([0.31794872, 0.47216891, 0.87159715]), array([ 443, 1295, 3876]))\n",
      "[[  93  183  167]\n",
      " [  17  492  786]\n",
      " [  32  114 3730]]\n",
      "\n",
      "\n",
      "Accuracy for BernoulliNB model = 0.7452796579978624\n",
      "(array([0.81415929, 0.60291439, 0.75949111]), array([0.20767494, 0.25559846, 0.97033024]), array([0.33093525, 0.35900217, 0.85206162]), array([ 443, 1295, 3876]))\n",
      "[[  92  106  245]\n",
      " [  18  331  946]\n",
      " [   3  112 3761]]\n",
      "\n",
      "\n",
      "Accuracy for LogisticRegression model = 0.8314926968293552\n",
      "(array([0.78647687, 0.73102786, 0.85880708]), array([0.49887133, 0.58764479, 0.95098039]), array([0.61049724, 0.6515411 , 0.90254652]), array([ 443, 1295, 3876]))\n",
      "[[ 221  104  118]\n",
      " [  46  761  488]\n",
      " [  14  176 3686]]\n",
      "\n",
      "\n",
      "Accuracy for SGDClassifier model = 0.8156394727467047\n",
      "(array([0.6909621 , 0.71298174, 0.84924154]), array([0.53498871, 0.54285714, 0.93885449]), array([0.60305344, 0.61639632, 0.89180248]), array([ 443, 1295, 3876]))\n",
      "[[ 237   79  127]\n",
      " [  73  703  519]\n",
      " [  33  204 3639]]\n",
      "\n",
      "\n",
      "Accuracy for LinearSVC model = 0.8265051656572854\n",
      "(array([0.74750831, 0.72034716, 0.85781104]), array([0.50790068, 0.57683398, 0.94633643]), array([0.60483871, 0.6406518 , 0.89990186]), array([ 443, 1295, 3876]))\n",
      "[[ 225  102  116]\n",
      " [  56  747  492]\n",
      " [  20  188 3668]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [MNB_clf, BNB_clf, LogReg_clf, SGD_clf, SVC_clf]\n",
    "for model in classifiers:\n",
    "    name = str(model).split('(')[0]\n",
    "    predictions = model.predict(X_test)\n",
    "    print (\"Accuracy for %s model = %s\" % (name, accuracy_score(my_target_test, predictions)))\n",
    "    print(precision_recall_fscore_support(my_target_test, predictions))\n",
    "    print(confusion_matrix(my_target_test, predictions))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = EnsembleClassifier(MNB_clf, BNB_clf, LogReg_clf, SGD_clf, SVC_clf)\n",
    "ensemble_preds = [ensemble_clf.classify(features) for features in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model = 0.8845742785892412\n",
      "(array([0.9009009 , 0.82309125, 0.89897789]), array([0.65359477, 0.69442262, 0.97424008]), array([0.75757576, 0.75330209, 0.93509705]), array([ 459, 1273, 3882]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy for model = %s\" % (accuracy_score(my_target_test, ensemble_preds)))\n",
    "print(precision_recall_fscore_support(my_target_test, ensemble_preds))\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
