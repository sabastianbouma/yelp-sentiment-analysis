{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "import re, string, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = pd.read_csv(r\"datasets/review_text_train.csv\", index_col = False, delimiter = ',', header=0)\n",
    "meta_train = pd.read_csv(r\"datasets/review_meta_train.csv\", index_col = False, delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = pd.read_csv(r\"datasets/review_text_test.csv\", index_col = False, delimiter = ',', header=0)\n",
    "meta_test = pd.read_csv(r\"datasets/review_meta_test.csv\", index_col = False, delimiter = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>vote_funny</th>\n",
       "      <th>vote_cool</th>\n",
       "      <th>vote_useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10/17/2011</td>\n",
       "      <td>WwAdD9wjkLqZHOO5</td>\n",
       "      <td>CY9iLsE2z_yLhLqJdD1WGw</td>\n",
       "      <td>cQnY_VneZisfUAqcbuEuKg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3/19/2007</td>\n",
       "      <td>Rd-Vra4drjDI8AQCXf6yTA</td>\n",
       "      <td>6feRQ3I9RpxRlEX7gPuJRg</td>\n",
       "      <td>sfWMOqUEp8S2adDeJp7Kzg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12/27/2008</td>\n",
       "      <td>mJD</td>\n",
       "      <td>RQs0smGxdXIlBqqlNP7pNg</td>\n",
       "      <td>2WoMT3wSpp9vxZeTv6u-cw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6/1/2010</td>\n",
       "      <td>J-xkladMPiVZFVhIbXLNEQ</td>\n",
       "      <td>q6EF83uL2lFRtnWwrfaYGA</td>\n",
       "      <td>AqgG-1aD6JYj9D6OmBWO3w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9/4/2012</td>\n",
       "      <td>jOMycoLCy79-256vNxl1kA</td>\n",
       "      <td>erZZ9K9wgdSswAm6TEh7Qw</td>\n",
       "      <td>boE4Ahsssqic7o5wQLI04w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7013</td>\n",
       "      <td>1/22/2010</td>\n",
       "      <td>QcCptbqQUgYwqeKz6Roncg</td>\n",
       "      <td>wISjGJS3bb6dh1rs2f1c1Q</td>\n",
       "      <td>jGiKIJCVLZHXQDSNnSLPsw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7014</td>\n",
       "      <td>6/14/2012</td>\n",
       "      <td>LG3FrYu03BCqQ-TAGsbowA</td>\n",
       "      <td>0eoCRbkKsEj8iv2Aow2ong</td>\n",
       "      <td>oEFJ29zAQaCNnQzebHQvpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7015</td>\n",
       "      <td>5/10/2010</td>\n",
       "      <td>Y2IKY1Nbmt2rjbiVyJoSSg</td>\n",
       "      <td>eiMZGw1zY8xwk1Xc3GM8lw</td>\n",
       "      <td>jGiKIJCVLZHXQDSNnSLPsw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7016</td>\n",
       "      <td>6/9/2011</td>\n",
       "      <td>OrKMrbD8J2J-0jLPip6ifA</td>\n",
       "      <td>L80nu6pXxl07zb_IKn0ZLw</td>\n",
       "      <td>UQ3cGi3GdBljE3i2_qLcBQ</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7017</td>\n",
       "      <td>12/8/2009</td>\n",
       "      <td>GAbxiT96Hs-wcvl2HT4AVw</td>\n",
       "      <td>cmrrkHcGmFcy68k372Jp0w</td>\n",
       "      <td>oEFJ29zAQaCNnQzebHQvpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7018 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date               review_id             reviewer_id  \\\n",
       "0     10/17/2011        WwAdD9wjkLqZHOO5  CY9iLsE2z_yLhLqJdD1WGw   \n",
       "1      3/19/2007  Rd-Vra4drjDI8AQCXf6yTA  6feRQ3I9RpxRlEX7gPuJRg   \n",
       "2     12/27/2008                     mJD  RQs0smGxdXIlBqqlNP7pNg   \n",
       "3       6/1/2010  J-xkladMPiVZFVhIbXLNEQ  q6EF83uL2lFRtnWwrfaYGA   \n",
       "4       9/4/2012  jOMycoLCy79-256vNxl1kA  erZZ9K9wgdSswAm6TEh7Qw   \n",
       "...          ...                     ...                     ...   \n",
       "7013   1/22/2010  QcCptbqQUgYwqeKz6Roncg  wISjGJS3bb6dh1rs2f1c1Q   \n",
       "7014   6/14/2012  LG3FrYu03BCqQ-TAGsbowA  0eoCRbkKsEj8iv2Aow2ong   \n",
       "7015   5/10/2010  Y2IKY1Nbmt2rjbiVyJoSSg  eiMZGw1zY8xwk1Xc3GM8lw   \n",
       "7016    6/9/2011  OrKMrbD8J2J-0jLPip6ifA  L80nu6pXxl07zb_IKn0ZLw   \n",
       "7017   12/8/2009  GAbxiT96Hs-wcvl2HT4AVw  cmrrkHcGmFcy68k372Jp0w   \n",
       "\n",
       "                 business_id  vote_funny  vote_cool  vote_useful  \n",
       "0     cQnY_VneZisfUAqcbuEuKg           2          1            3  \n",
       "1     sfWMOqUEp8S2adDeJp7Kzg           0          1            3  \n",
       "2     2WoMT3wSpp9vxZeTv6u-cw           0          0            0  \n",
       "3     AqgG-1aD6JYj9D6OmBWO3w           0          0            0  \n",
       "4     boE4Ahsssqic7o5wQLI04w           0          0            0  \n",
       "...                      ...         ...        ...          ...  \n",
       "7013  jGiKIJCVLZHXQDSNnSLPsw           0          0            0  \n",
       "7014  oEFJ29zAQaCNnQzebHQvpg           2          0            0  \n",
       "7015  jGiKIJCVLZHXQDSNnSLPsw           0          0            1  \n",
       "7016  UQ3cGi3GdBljE3i2_qLcBQ           3          0            4  \n",
       "7017  oEFJ29zAQaCNnQzebHQvpg           0          3            3  \n",
       "\n",
       "[7018 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "all_reviews = []\n",
    "all_words = []\n",
    "allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "\n",
    "for i in range(0,text_train.shape[0]):\n",
    "    text = text_train.at[i,'review']\n",
    "    rating = meta_train.at[i,'rating']\n",
    "    tup = (text,rating)\n",
    "    all_reviews.append(tup)\n",
    "    \n",
    "    cleaned = re.sub(r'[^(a-zA-Z)\\s]',' ', text)\n",
    "    tokenized = word_tokenize(cleaned)\n",
    "    \n",
    "    stopped = [w for w in tokenized if not w in stop_words]\n",
    "    pos = nltk.pos_tag(stopped)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for token, tag in pos:\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "        if tag[0] in allowed_word_types:\n",
    "            all_words.append(token.lower())\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "word_features = list(all_words.keys())[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jeff graham'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = ''\n",
    "te+='jeff'\n",
    "te+=' '\n",
    "te+='graham'\n",
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_path): \n",
    "    classifier_f = open(file_path, \"rb\")\n",
    "    classifier = pickle.load(classifier_f)\n",
    "    classifier_f.close()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = load_model(\"pickled_algos/reviews.pickle\")\n",
    "word_features = load_model(\"pickled_algos/word_features5k.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in all_reviews]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featuresets)\n",
    "lim = int(len(featuresets)*.8)\n",
    "trainnn = featuresets[:lim]\n",
    "testtt = featuresets[lim:]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       It is 10am on a Monday morning and my wife say...\n",
       "1       I came here with a friend for her work thing -...\n",
       "2       ATTENTION!!! DO NOT GO TO THIS RESTAURANT EVER...\n",
       "3       I agree, with Jonathan S. - this place is a 3....\n",
       "4       First visit to Chicago, and a friend recommend...\n",
       "                              ...                        \n",
       "7013    I LOVED XOCO! It was amazing! My friends and I...\n",
       "7014    Place is pretty dark. A place to chat with a g...\n",
       "7015    Get to Xoco and you can order yourself a tasty...\n",
       "7016    I'm writing this less than 10 minutes after re...\n",
       "7017    I love how this gem is hidden. I felt like Ali...\n",
       "Name: review, Length: 7018, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_kaggle = [find_features(rev) for rev in text_test['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LogReg_clf2 = SklearnClassifier(LogisticRegression())\n",
    "LogReg_clf2.train(featuresets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [LogReg_clf2.classify(r) for r in test_set_kaggle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 73.35233345208407\n",
      "Most Informative Features\n",
      "                  rudely = True                1 : 5      =    214.4 : 1.0\n",
      "                inedible = True                1 : 5      =     99.3 : 1.0\n",
      "               tasteless = True                1 : 5      =     91.4 : 1.0\n",
      "               insulting = True                1 : 5      =     89.6 : 1.0\n",
      "            unacceptable = True                1 : 5      =     68.6 : 1.0\n",
      "                  refund = True                1 : 5      =     50.5 : 1.0\n",
      "                   worst = True                1 : 5      =     46.7 : 1.0\n",
      "                 apology = True                1 : 5      =     43.2 : 1.0\n",
      "                downhill = True                1 : 5      =     43.0 : 1.0\n",
      "               disgusted = True                1 : 5      =     43.0 : 1.0\n",
      "                   awful = True                1 : 5      =     41.1 : 1.0\n",
      "                    rude = True                1 : 5      =     38.1 : 1.0\n",
      "                  horrid = True                1 : 5      =     35.3 : 1.0\n",
      "                 refused = True                1 : 5      =     34.7 : 1.0\n",
      "                  ripped = True                1 : 5      =     33.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainnn)\n",
    "\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testtt))*100)\n",
    "\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5285d9d1ad1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reviews.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "save_reviews = open(\"reviews.pickle\",\"wb\")\n",
    "pickle.dump(all_reviews, save_reviews)\n",
    "save_reviews.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_word_features = open(\"word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 73.35233345208407\n",
      "Most Informative Features\n",
      "                  rudely = True                1 : 5      =    214.4 : 1.0\n",
      "                inedible = True                1 : 5      =     99.3 : 1.0\n",
      "               tasteless = True                1 : 5      =     91.4 : 1.0\n",
      "               insulting = True                1 : 5      =     89.6 : 1.0\n",
      "            unacceptable = True                1 : 5      =     68.6 : 1.0\n",
      "                  refund = True                1 : 5      =     50.5 : 1.0\n",
      "                   worst = True                1 : 5      =     46.7 : 1.0\n",
      "                 apology = True                1 : 5      =     43.2 : 1.0\n",
      "                downhill = True                1 : 5      =     43.0 : 1.0\n",
      "               disgusted = True                1 : 5      =     43.0 : 1.0\n",
      "                   awful = True                1 : 5      =     41.1 : 1.0\n",
      "                    rude = True                1 : 5      =     38.1 : 1.0\n",
      "                  horrid = True                1 : 5      =     35.3 : 1.0\n",
      "                 refused = True                1 : 5      =     34.7 : 1.0\n",
      "                  ripped = True                1 : 5      =     33.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testtt))*100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy percent: 83.55895974349839\n"
     ]
    }
   ],
   "source": [
    "MNB_clf = SklearnClassifier(MultinomialNB())\n",
    "MNB_clf.train(trainnn)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_clf, testtt))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB_classifier accuracy percent: 73.26327039543997\n"
     ]
    }
   ],
   "source": [
    "BNB_clf = SklearnClassifier(BernoulliNB())\n",
    "BNB_clf.train(trainnn)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BNB_clf, testtt))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 83.68364802280014\n"
     ]
    }
   ],
   "source": [
    "LogReg_clf = SklearnClassifier(LogisticRegression())\n",
    "LogReg_clf.train(trainnn)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogReg_clf, testtt))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify(LogReg_clf, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 83.23833273957962\n"
     ]
    }
   ],
   "source": [
    "SGD_clf = SklearnClassifier(SGDClassifier())\n",
    "SGD_clf.train(trainnn)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGD_clf, testtt))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabastianbouma/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "SVC_clf = SklearnClassifier(SVC())\n",
    "SVC_clf.train(trainnn)\n",
    "print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_clf, testtt))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pickle(c, file_name): \n",
    "    save_classifier = open(file_name, 'wb')\n",
    "    pickle.dump(c, save_classifier)\n",
    "    save_classifier.close()\n",
    "\n",
    "classifiers_dict = {'ONB': [classifier, 'pickled_algos/ONB_clf.pickle'],\n",
    "                    'MNB': [MNB_clf, 'pickled_algos/MNB_clf.pickle'],\n",
    "                    'BNB': [BNB_clf, 'pickled_algos/BNB_clf.pickle'],\n",
    "                    'LogReg': [LogReg_clf, 'pickled_algos/LogReg_clf.pickle'],\n",
    "                    'SGD': [SGD_clf, 'pickled_algos/SGD_clf.pickle']}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf, listy in classifiers_dict.items(): \n",
    "    create_pickle(listy[0], listy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triple lit\n"
     ]
    }
   ],
   "source": [
    "print('triple lit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [r[1] for r in testtt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONB\n"
     ]
    }
   ],
   "source": [
    "for a, b in classifiers_dict.items():\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for clf, listy in classifiers_dict.items(): \n",
    "    predictions[clf] = [listy[0].classify(r[0]) for r in testtt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b04bf8af61e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlisty\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlisty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesttt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# getting predictions for the testing set by looping over each reviews featureset tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-b04bf8af61e1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlisty\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlisty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesttt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# getting predictions for the testing set by looping over each reviews featureset tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/nltk/classify/naivebayes.py\u001b[0m in \u001b[0;36mprob_classify\u001b[0;34m(self, featureset)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_probdist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0mfeature_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_probdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0mlogprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfeature_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_scores = {}\n",
    "\n",
    "for clf, listy in classifiers_dict.items(): \n",
    "    # getting predictions for the testing set by looping over each reviews featureset tuple\n",
    "    # The first elemnt of the tuple is the feature set and the second element is the label \n",
    "    acc_scores[clf] = accuracy_score(ground_truth, predictions[clf])\n",
    "    print(f'Accuracy_score {clf}: {acc_scores[clf]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-bc4613b0868e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# The first elemnt of the tuple is the feature set and the second element is the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlisty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesttt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf1_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'f1_score {clf}: {f1_scores[clf]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1253\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1255\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "ground_truth = [r[1] for r in testtt]\n",
    "predictions = {}\n",
    "f1_scores = {}\n",
    "for clf, listy in classifiers_dict.items(): \n",
    "    # getting predictions for the testing set by looping over each reviews featureset tuple\n",
    "    # The first elemnt of the tuple is the feature set and the second element is the label \n",
    "    predictions[clf] = [listy[0].classify(r[0]) for r in testtt]\n",
    "    f1_scores[clf] = f1_score(ground_truth, predictions[clf])\n",
    "    print(f'f1_score {clf}: {f1_scores[clf]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from collections import Counter\n",
    "\n",
    "# Defininig the ensemble model class \n",
    "\n",
    "class EnsembleClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    # returns the classification based on majority of votes\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return Counter(votes).most_common(1)\n",
    "    # a simple measurement the degree of confidence in the classification \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ensemble classifier \n",
    "ensemble_clf = EnsembleClassifier(classifier, MNB_clf, BNB_clf, LogReg_clf, SGD_clf)\n",
    "\n",
    "# List of only feature dictionary from the featureset list of tuples \n",
    "feature_list = [f[0] for f in testtt]\n",
    "\n",
    "# Looping over each to classify each review\n",
    "ensemble_preds = [ensemble_clf.classify(features) for features in feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = [a[0][0] for a in ensemble_preds]\n",
    "e2 = [a[0][1] for a in ensemble_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300676879230495"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ground_truth,e1, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('quaaaaaad lit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28068"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dear': False,\n",
       "  'leave': False,\n",
       "  'menu': False,\n",
       "  'look': False,\n",
       "  'exceptionally': False,\n",
       "  'want': False,\n",
       "  'eat': False,\n",
       "  'multiple': False,\n",
       "  'many': False,\n",
       "  'consistent': False,\n",
       "  'overprice': False,\n",
       "  'cook': False,\n",
       "  'go': True,\n",
       "  'get': False,\n",
       "  'undercooked': False,\n",
       "  'actually': False,\n",
       "  'attempt': False,\n",
       "  'dessert': False,\n",
       "  'donuts': False,\n",
       "  'taste': False,\n",
       "  'unchanged': False,\n",
       "  'fryer': False,\n",
       "  'smell': False,\n",
       "  'hit': False,\n",
       "  'table': False,\n",
       "  'pre': False,\n",
       "  'portion': False,\n",
       "  'glad': False,\n",
       "  'great': False,\n",
       "  'whiskey': False,\n",
       "  'face': False,\n",
       "  'ever': False,\n",
       "  'longman': False,\n",
       "  'memorable': False,\n",
       "  'delish': False,\n",
       "  'think': False,\n",
       "  'show': False,\n",
       "  'close': False,\n",
       "  'decide': False,\n",
       "  'drive': False,\n",
       "  'ecstatic': False,\n",
       "  'open': False,\n",
       "  'sit': False,\n",
       "  'outside': False,\n",
       "  'white': False,\n",
       "  'server': False,\n",
       "  'outstanding': False,\n",
       "  'friendly': False,\n",
       "  'good': False,\n",
       "  'benedict': False,\n",
       "  'meal': False,\n",
       "  'belly': False,\n",
       "  'sandwich': False,\n",
       "  'salad': False,\n",
       "  'heaven': False,\n",
       "  'perfectly': False,\n",
       "  'poach': False,\n",
       "  'crab': False,\n",
       "  'creamy': False,\n",
       "  'bacon': False,\n",
       "  'fabulous': False,\n",
       "  'first': False,\n",
       "  'finish': False,\n",
       "  'sweet': False,\n",
       "  'best': False,\n",
       "  'wait': False,\n",
       "  'brunch': False,\n",
       "  'come': False,\n",
       "  'give': False,\n",
       "  'lie': False,\n",
       "  'say': True,\n",
       "  'single': False,\n",
       "  'back': False,\n",
       "  'sample': False,\n",
       "  'still': False,\n",
       "  'plan': False,\n",
       "  'star': False,\n",
       "  'really': False,\n",
       "  'efficient': False,\n",
       "  'find': False,\n",
       "  'generous': False,\n",
       "  'brew': False,\n",
       "  'spectacular': True,\n",
       "  'mood': False,\n",
       "  'feel': False,\n",
       "  'always': False,\n",
       "  'love': False,\n",
       "  'belgian': False,\n",
       "  'top': False,\n",
       "  'yogurt': False,\n",
       "  'fresh': True,\n",
       "  'also': False,\n",
       "  'quite': False,\n",
       "  'tasty': True,\n",
       "  'try': False,\n",
       "  'live': False,\n",
       "  'block': False,\n",
       "  'away': True,\n",
       "  'breakfast': False,\n",
       "  'order': False,\n",
       "  'happy': False,\n",
       "  'bring': False,\n",
       "  'old': False,\n",
       "  'enjoy': False,\n",
       "  'welcome': False,\n",
       "  'enough': False,\n",
       "  'cater': False,\n",
       "  'rave': False,\n",
       "  'reasonably': False,\n",
       "  'price': False,\n",
       "  'meat': False,\n",
       "  'tastic': False,\n",
       "  'so': False,\n",
       "  'much': False,\n",
       "  'mad': False,\n",
       "  'need': False,\n",
       "  'catch': False,\n",
       "  'quick': False,\n",
       "  'long': False,\n",
       "  'fortunately': False,\n",
       "  'early': False,\n",
       "  'eaten': False,\n",
       "  'definitely': True,\n",
       "  'nice': False,\n",
       "  'loud': False,\n",
       "  'little': False,\n",
       "  'appreciate': False,\n",
       "  'park': False,\n",
       "  'fine': False,\n",
       "  'far': False,\n",
       "  'nutella': False,\n",
       "  'else': False,\n",
       "  'doused': False,\n",
       "  'heavy': False,\n",
       "  'dish': False,\n",
       "  'seem': False,\n",
       "  'blow': False,\n",
       "  'delicious': False,\n",
       "  'sausages': False,\n",
       "  'keen': False,\n",
       "  'obviously': False,\n",
       "  'adventurous': False,\n",
       "  'wrong': False,\n",
       "  'constantly': False,\n",
       "  'read': False,\n",
       "  'cool': False,\n",
       "  'follow': False,\n",
       "  'make': False,\n",
       "  'thread': False,\n",
       "  'start': False,\n",
       "  'nearly': False,\n",
       "  'border': False,\n",
       "  'obsess': False,\n",
       "  'attentive': False,\n",
       "  'refill': False,\n",
       "  'yet': False,\n",
       "  'disappoint': False,\n",
       "  'chef': False,\n",
       "  'homemade': False,\n",
       "  'english': False,\n",
       "  'mean': False,\n",
       "  'warm': False,\n",
       "  'pumpkin': False,\n",
       "  'die': False,\n",
       "  'gotten': False,\n",
       "  'free': False,\n",
       "  'organic': False,\n",
       "  'local': False,\n",
       "  'overall': True,\n",
       "  'beautifully': False,\n",
       "  'plat': False,\n",
       "  'special': False,\n",
       "  'solid': True,\n",
       "  'desire': False,\n",
       "  'truly': False,\n",
       "  'kick': False,\n",
       "  'main': False,\n",
       "  'right': False,\n",
       "  'travel': False,\n",
       "  'whole': False,\n",
       "  'honest': False,\n",
       "  'uber': False,\n",
       "  'din': False,\n",
       "  'thrill': False,\n",
       "  'convinced': False,\n",
       "  'raspberry': False,\n",
       "  'ale': False,\n",
       "  'easily': False,\n",
       "  'call': False,\n",
       "  'absolutely': False,\n",
       "  'sublime': False,\n",
       "  'cheese': False,\n",
       "  'ranch': False,\n",
       "  'dip': False,\n",
       "  'perhaps': False,\n",
       "  'ultimate': False,\n",
       "  'fat': False,\n",
       "  'fit': False,\n",
       "  'know': False,\n",
       "  'commit': False,\n",
       "  'tell': False,\n",
       "  'several': True,\n",
       "  'atmosphere': False,\n",
       "  'bad': True,\n",
       "  'new': False,\n",
       "  'trendy': False,\n",
       "  'sure': False,\n",
       "  'rather': False,\n",
       "  'tattooed': False,\n",
       "  'somethin': False,\n",
       "  'clique': False,\n",
       "  'big': False,\n",
       "  'literally': False,\n",
       "  'figuratively': False,\n",
       "  'favorite': False,\n",
       "  'indian': False,\n",
       "  'forward': False,\n",
       "  'do': False,\n",
       "  'par': False,\n",
       "  'extremely': False,\n",
       "  'accompany': False,\n",
       "  'scrumptious': False,\n",
       "  'very': False,\n",
       "  'bland': False,\n",
       "  'scant': False,\n",
       "  'tasted': False,\n",
       "  'reheat': False,\n",
       "  'worth': False,\n",
       "  'take': False,\n",
       "  'unacceptable': False,\n",
       "  'hard': False,\n",
       "  'press': False,\n",
       "  'somewhere': False,\n",
       "  'publican': False,\n",
       "  'last': True,\n",
       "  'feast': False,\n",
       "  'thinly': False,\n",
       "  'slice': False,\n",
       "  'serrano': False,\n",
       "  'rinds': False,\n",
       "  'super': False,\n",
       "  'forget': False,\n",
       "  'describe': False,\n",
       "  'magical': False,\n",
       "  'spreadable': False,\n",
       "  'accord': False,\n",
       "  'ask': False,\n",
       "  'suggest': False,\n",
       "  'cover': False,\n",
       "  'important': False,\n",
       "  'seriously': False,\n",
       "  'awesome': False,\n",
       "  'real': False,\n",
       "  'yes': False,\n",
       "  'hundred': False,\n",
       "  'rich': False,\n",
       "  'home': False,\n",
       "  'sick': False,\n",
       "  'suckling': False,\n",
       "  'tender': False,\n",
       "  'caramely': False,\n",
       "  'ouside': False,\n",
       "  'soft': False,\n",
       "  'pickiness': False,\n",
       "  'skip': False,\n",
       "  'side': False,\n",
       "  'put': False,\n",
       "  'probably': True,\n",
       "  'roll': False,\n",
       "  'amaze': False,\n",
       "  'unfortunately': False,\n",
       "  'change': False,\n",
       "  'return': False,\n",
       "  'suspect': False,\n",
       "  'soon': False,\n",
       "  'next': True,\n",
       "  'size': False,\n",
       "  'stuffed': False,\n",
       "  'amazing': False,\n",
       "  'meek': False,\n",
       "  'oh': False,\n",
       "  'expensive': False,\n",
       "  'affordable': False,\n",
       "  'not': False,\n",
       "  'true': False,\n",
       "  'approximately': False,\n",
       "  'accomplish': False,\n",
       "  'fill': False,\n",
       "  'now': False,\n",
       "  'crepe': False,\n",
       "  'satisfying': False,\n",
       "  'unfulfilled': False,\n",
       "  'honestly': False,\n",
       "  'mine': False,\n",
       "  'mushroom': False,\n",
       "  'cubes': False,\n",
       "  'soup': False,\n",
       "  'hold': False,\n",
       "  'previous': False,\n",
       "  'feature': False,\n",
       "  'update': False,\n",
       "  'reflect': False,\n",
       "  'pathetic': False,\n",
       "  'offer': False,\n",
       "  'well': False,\n",
       "  'suppose': False,\n",
       "  'lose': False,\n",
       "  'never': True,\n",
       "  'fantastic': False,\n",
       "  'help': False,\n",
       "  'explain': False,\n",
       "  'happen': False,\n",
       "  'restaurant': False,\n",
       "  'wine': False,\n",
       "  'equally': False,\n",
       "  'carmelized': False,\n",
       "  'lobster': False,\n",
       "  'least': False,\n",
       "  'mainly': False,\n",
       "  'milk': False,\n",
       "  'exceptional': False,\n",
       "  'decent': False,\n",
       "  'refresh': False,\n",
       "  'cafe': False,\n",
       "  'short': False,\n",
       "  'executed': False,\n",
       "  'contemporary': False,\n",
       "  'american': False,\n",
       "  'punctuate': False,\n",
       "  'seasonal': False,\n",
       "  'weekly': False,\n",
       "  'daily': False,\n",
       "  'see': False,\n",
       "  'casseroles': False,\n",
       "  'serve': False,\n",
       "  'recognize': False,\n",
       "  'equal': False,\n",
       "  'minimal': False,\n",
       "  'fast': False,\n",
       "  'play': False,\n",
       "  'encourage': False,\n",
       "  'bus': False,\n",
       "  'negative': False,\n",
       "  'allow': False,\n",
       "  'non': False,\n",
       "  'invasive': False,\n",
       "  'seating': False,\n",
       "  'tight': False,\n",
       "  'become': False,\n",
       "  'scarce': False,\n",
       "  'expect': False,\n",
       "  'fifteen': False,\n",
       "  'minimum': False,\n",
       "  'seat': False,\n",
       "  'popular': False,\n",
       "  'teach': False,\n",
       "  'even': False,\n",
       "  'couple': False,\n",
       "  'deep': False,\n",
       "  'guy': False,\n",
       "  'original': False,\n",
       "  'patty': False,\n",
       "  'pizza': True,\n",
       "  'sized': False,\n",
       "  'hang': False,\n",
       "  'fun': False,\n",
       "  'challenge': False,\n",
       "  'possible': False,\n",
       "  'finally': False,\n",
       "  'al': False,\n",
       "  'use': False,\n",
       "  'ahead': False,\n",
       "  'arrive': False,\n",
       "  'pm': False,\n",
       "  'already': False,\n",
       "  'senior': False,\n",
       "  'notice': False,\n",
       "  'hostess': False,\n",
       "  'spent': False,\n",
       "  'wish': False,\n",
       "  'remember': False,\n",
       "  'small': False,\n",
       "  'run': False,\n",
       "  'pretty': True,\n",
       "  'chilly': False,\n",
       "  'gon': False,\n",
       "  'especially': False,\n",
       "  'hear': False,\n",
       "  'prepare': False,\n",
       "  'mousse': False,\n",
       "  'waiter': False,\n",
       "  'cinnamon': False,\n",
       "  'bit': False,\n",
       "  'savory': False,\n",
       "  'started': False,\n",
       "  'seared': False,\n",
       "  'braise': False,\n",
       "  'oxtail': False,\n",
       "  'black': False,\n",
       "  'scallop': False,\n",
       "  'leg': False,\n",
       "  'venison': False,\n",
       "  'fennel': False,\n",
       "  'lick': False,\n",
       "  'duck': False,\n",
       "  'perfect': False,\n",
       "  'clean': False,\n",
       "  'full': False,\n",
       "  'sleep': False,\n",
       "  'artfully': False,\n",
       "  'decorate': False,\n",
       "  'romantic': False,\n",
       "  'complimentary': False,\n",
       "  'cornbread': False,\n",
       "  'enormous': False,\n",
       "  'dream': False,\n",
       "  'stuff': False,\n",
       "  'casual': False,\n",
       "  'modern': False,\n",
       "  'defend': False,\n",
       "  'pizzeria': False,\n",
       "  'point': False,\n",
       "  'certain': False,\n",
       "  'base': False,\n",
       "  'precisely': False,\n",
       "  'anywhere': False,\n",
       "  'soak': False,\n",
       "  'personally': False,\n",
       "  'pizzas': False,\n",
       "  'juicy': False,\n",
       "  'flavorful': False,\n",
       "  'frozen': False,\n",
       "  'incredibly': False,\n",
       "  'balance': False,\n",
       "  'thaw': False,\n",
       "  'prior': False,\n",
       "  'oven': False,\n",
       "  'write': False,\n",
       "  'begin': False,\n",
       "  'add': False,\n",
       "  'unique': False,\n",
       "  'absolute': False,\n",
       "  'kid': False,\n",
       "  'inbetween': False,\n",
       "  'check': False,\n",
       "  'authentic': False,\n",
       "  'comfortable': False,\n",
       "  'kill': False,\n",
       "  'stop': False,\n",
       "  'thin': False,\n",
       "  'however': False,\n",
       "  'place': False,\n",
       "  'helpful': False,\n",
       "  'toasted': False,\n",
       "  'handmade': False,\n",
       "  'greasy': False,\n",
       "  'afraid': False,\n",
       "  'http': False,\n",
       "  'waitress': False,\n",
       "  'recommended': False,\n",
       "  'poison': False,\n",
       "  'regularly': False,\n",
       "  'warn': False,\n",
       "  'crowd': False,\n",
       "  'egg': False,\n",
       "  'burrito': False,\n",
       "  'share': False,\n",
       "  'w': False,\n",
       "  'yummy': False,\n",
       "  'satisfied': False,\n",
       "  'different': False,\n",
       "  'unbelievable': False,\n",
       "  'pair': False,\n",
       "  'able': False,\n",
       "  'huge': False,\n",
       "  'list': False,\n",
       "  'work': False,\n",
       "  'rude': False,\n",
       "  'pack': False,\n",
       "  'family': False,\n",
       "  'mother': False,\n",
       "  'pick': False,\n",
       "  'due': False,\n",
       "  'yelp': False,\n",
       "  'boy': False,\n",
       "  'believe': False,\n",
       "  'prefer': False,\n",
       "  'young': False,\n",
       "  'deee': False,\n",
       "  'lish': False,\n",
       "  'scallops': False,\n",
       "  'rest': False,\n",
       "  'stand': False,\n",
       "  'picky': False,\n",
       "  'impress': False,\n",
       "  'bite': True,\n",
       "  'like': False,\n",
       "  'chicken': False,\n",
       "  'friend': True,\n",
       "  'maybe': True,\n",
       "  'excellent': False,\n",
       "  'boisterous': False,\n",
       "  'invite': False,\n",
       "  'flawless': False,\n",
       "  'regardless': False,\n",
       "  'qo': False,\n",
       "  'experience': True,\n",
       "  'hide': False,\n",
       "  'friends': False,\n",
       "  'stumble': False,\n",
       "  'purchase': False,\n",
       "  'beers': False,\n",
       "  'half': False,\n",
       "  'handle': False,\n",
       "  'large': False,\n",
       "  'late': False,\n",
       "  'move': False,\n",
       "  'regular': False,\n",
       "  'pushy': False,\n",
       "  'rush': False,\n",
       "  'let': False,\n",
       "  'empty': False,\n",
       "  'loiter': False,\n",
       "  'whip': False,\n",
       "  'martini': False,\n",
       "  'recommend': False,\n",
       "  'pastas': False,\n",
       "  'fan': False,\n",
       "  'crust': False,\n",
       "  'doughy': False,\n",
       "  'ta': False,\n",
       "  'low': False,\n",
       "  'excite': False,\n",
       "  'bar': False,\n",
       "  'opt': False,\n",
       "  'drink': False,\n",
       "  'then': False,\n",
       "  'review': False,\n",
       "  'admit': False,\n",
       "  'hot': False,\n",
       "  'exotic': False,\n",
       "  'wild': False,\n",
       "  'shove': False,\n",
       "  'case': False,\n",
       "  'crazy': False,\n",
       "  'yeah': False,\n",
       "  'double': False,\n",
       "  'friday': False,\n",
       "  'saturday': False,\n",
       "  'disgustingly': False,\n",
       "  'saw': False,\n",
       "  'head': False,\n",
       "  'buy': False,\n",
       "  'consist': False,\n",
       "  'raise': False,\n",
       "  'sauce': True,\n",
       "  'onion': False,\n",
       "  'pass': False,\n",
       "  'palatable': False,\n",
       "  'combo': False,\n",
       "  'ring': False,\n",
       "  'hormone': False,\n",
       "  'store': False,\n",
       "  'geek': False,\n",
       "  'high': False,\n",
       "  'difficult': False,\n",
       "  'otherwise': False,\n",
       "  'anyway': False,\n",
       "  'guarantee': False,\n",
       "  'xoco': False,\n",
       "  'consider': False,\n",
       "  'remarkable': False,\n",
       "  'oil': False,\n",
       "  'provide': False,\n",
       "  'foot': False,\n",
       "  'quickly': False,\n",
       "  'distinctly': False,\n",
       "  'bubble': False,\n",
       "  'exactly': False,\n",
       "  'ago': False,\n",
       "  'eerily': False,\n",
       "  'detail': False,\n",
       "  'injure': False,\n",
       "  'arm': False,\n",
       "  'reader': False,\n",
       "  'temporarily': False,\n",
       "  'buff': False,\n",
       "  'jog': False,\n",
       "  'exact': False,\n",
       "  'scrawny': False,\n",
       "  'clearly': False,\n",
       "  'weird': False,\n",
       "  'seriousness': False,\n",
       "  'entire': False,\n",
       "  'celebrate': False,\n",
       "  'medical': False,\n",
       "  'lot': False,\n",
       "  'draw': False,\n",
       "  'sight': False,\n",
       "  'understand': False,\n",
       "  'comment': False,\n",
       "  'sorry': False,\n",
       "  'just': True,\n",
       "  'extra': False,\n",
       "  'garlic': False,\n",
       "  'pink': False,\n",
       "  'fish': False,\n",
       "  'official': False,\n",
       "  'certainly': False,\n",
       "  'keep': False,\n",
       "  'smile': False,\n",
       "  'wag': False,\n",
       "  'lamb': False,\n",
       "  'hungry': False,\n",
       "  'recent': False,\n",
       "  'unsanitary': False,\n",
       "  'hooey': False,\n",
       "  'greek': False,\n",
       "  'tucked': False,\n",
       "  'growing': False,\n",
       "  'vietnamese': False,\n",
       "  'miss': False,\n",
       "  'decades': False,\n",
       "  'former': False,\n",
       "  'reopen': False,\n",
       "  'reminisce': False,\n",
       "  'greet': False,\n",
       "  'warmly': False,\n",
       "  'intimate': False,\n",
       "  'remind': False,\n",
       "  'visit': False,\n",
       "  'set': False,\n",
       "  'candle': False,\n",
       "  'anymore': False,\n",
       "  'sticky': False,\n",
       "  'sometimes': False,\n",
       "  'throw': False,\n",
       "  'desert': False,\n",
       "  'extensive': False,\n",
       "  'favorites': False,\n",
       "  'care': False,\n",
       "  'lucky': False,\n",
       "  'thankfully': False,\n",
       "  'plentiful': False,\n",
       "  'thick': False,\n",
       "  'depend': False,\n",
       "  'most': False,\n",
       "  'succeed': False,\n",
       "  'fail': False,\n",
       "  'certifiably': False,\n",
       "  'don': False,\n",
       "  'hesitate': False,\n",
       "  'alone': False,\n",
       "  'lament': False,\n",
       "  'cold': False,\n",
       "  'windy': False,\n",
       "  'receive': False,\n",
       "  'basically': False,\n",
       "  'onsite': False,\n",
       "  'butt': False,\n",
       "  'idiot': False,\n",
       "  'instead': False,\n",
       "  'idiotic': False,\n",
       "  'tabletop': False,\n",
       "  'sell': False,\n",
       "  'bet': False,\n",
       "  'quiet': False,\n",
       "  'stupid': False,\n",
       "  'subside': False,\n",
       "  'poor': False,\n",
       "  'matter': False,\n",
       "  'koreans': False,\n",
       "  'co': False,\n",
       "  'improve': False,\n",
       "  'korean': False,\n",
       "  'nicer': False,\n",
       "  'stubborn': False,\n",
       "  'angry': False,\n",
       "  'ladies': False,\n",
       "  'hate': False,\n",
       "  'tire': False,\n",
       "  'okay': False,\n",
       "  'moderate': False,\n",
       "  'hope': False,\n",
       "  'southern': False,\n",
       "  'coastal': False,\n",
       "  'tend': False,\n",
       "  'prix': False,\n",
       "  'fixe': False,\n",
       "  'almost': False,\n",
       "  'flavored': False,\n",
       "  'dress': False,\n",
       "  'entree': False,\n",
       "  'fingerling': False,\n",
       "  'bread': False,\n",
       "  'pudding': False,\n",
       "  'wow': False,\n",
       "  'ridiculously': False,\n",
       "  'mouth': False,\n",
       "  'include': False,\n",
       "  'north': False,\n",
       "  'coke': False,\n",
       "  'cherry': False,\n",
       "  'sizzle': False,\n",
       "  'butter': False,\n",
       "  'fancy': False,\n",
       "  'extras': False,\n",
       "  'mash': False,\n",
       "  'melt': False,\n",
       "  'fool': False,\n",
       "  'dicey': False,\n",
       "  'apparently': False,\n",
       "  'agree': False,\n",
       "  'aware': False,\n",
       "  'assume': False,\n",
       "  'pour': False,\n",
       "  'cramp': False,\n",
       "  'inconvenient': False,\n",
       "  'someones': False,\n",
       "  'incredible': False,\n",
       "  'latkes': False,\n",
       "  'german': False,\n",
       "  'dolly': False,\n",
       "  'outta': False,\n",
       "  'dinner': False,\n",
       "  'pancakes': False,\n",
       "  'usual': False,\n",
       "  'festival': False,\n",
       "  'walk': False,\n",
       "  'spot': False,\n",
       "  'limited': False,\n",
       "  'once': False,\n",
       "  'ordered': False,\n",
       "  'simple': False,\n",
       "  'centrally': False,\n",
       "  'locate': False,\n",
       "  'relatively': False,\n",
       "  'bright': False,\n",
       "  'cozy': False,\n",
       "  'mostly': False,\n",
       "  'tide': False,\n",
       "  'amount': False,\n",
       "  'less': False,\n",
       "  'pan': False,\n",
       "  'rubbery': False,\n",
       "  'ample': False,\n",
       "  'turkey': False,\n",
       "  'croissant': False,\n",
       "  'complain': False,\n",
       "  'brought': False,\n",
       "  'cost': False,\n",
       "  'smash': False,\n",
       "  'nowhere': False,\n",
       "  'appeal': False,\n",
       "  'satisfy': False,\n",
       "  'father': False,\n",
       "  'post': False,\n",
       "  'sad': False,\n",
       "  'infamous': False,\n",
       "  'dad': False,\n",
       "  'fairly': False,\n",
       "  'attribute': False,\n",
       "  'current': False,\n",
       "  'avoid': False,\n",
       "  'intimidated': False,\n",
       "  'possibly': False,\n",
       "  'plus': False,\n",
       "  'seasoned': False,\n",
       "  'rare': False,\n",
       "  'salads': False,\n",
       "  'japanese': False,\n",
       "  'grill': False,\n",
       "  'tip': False,\n",
       "  'indeed': False,\n",
       "  'floor': False,\n",
       "  'desperately': False,\n",
       "  'sadly': False,\n",
       "  'lowly': False,\n",
       "  'intern': False,\n",
       "  'professional': False,\n",
       "  'joy': False,\n",
       "  'additional': False,\n",
       "  'luck': False,\n",
       "  'fell': False,\n",
       "  'wont': False,\n",
       "  'recapture': False,\n",
       "  'present': False,\n",
       "  'compliment': False,\n",
       "  'familiar': False,\n",
       "  'complex': False,\n",
       "  'mustard': False,\n",
       "  'drop': False,\n",
       "  'apply': False,\n",
       "  'treat': False,\n",
       "  'cleansed': False,\n",
       "  'frankly': False,\n",
       "  'rat': False,\n",
       "  'disappear': False,\n",
       "  'halfway': False,\n",
       "  'replace': False,\n",
       "  'fiance': False,\n",
       "  'detract': False,\n",
       "  'prove': False,\n",
       "  'sum': False,\n",
       "  'independent': False,\n",
       "  'surprise': False,\n",
       "  'turn': False,\n",
       "  'highly': False,\n",
       "  'recently': False,\n",
       "  'impromptu': False,\n",
       "  'whim': False,\n",
       "  'spend': False,\n",
       "  'bed': False,\n",
       "  'smoke': False,\n",
       "  'bunch': False,\n",
       "  'cocktails': False,\n",
       "  'rent': False,\n",
       "  'delightful': False,\n",
       "  'drank': False,\n",
       "  'stick': False,\n",
       "  'snob': False,\n",
       "  'inherited': False,\n",
       "  'ruin': False,\n",
       "  'charm': False,\n",
       "  'properly': False,\n",
       "  'smoothly': False,\n",
       "  'deliciously': False,\n",
       "  'seafood': False,\n",
       "  'flown': False,\n",
       "  'carry': False,\n",
       "  'seasonally': False,\n",
       "  'available': False,\n",
       "  'decor': False,\n",
       "  'minor': False,\n",
       "  'accidentally': False,\n",
       "  'divvying': False,\n",
       "  'adore': False,\n",
       "  'anytime': False,\n",
       "  'specifically': False,\n",
       "  'lunch': False,\n",
       "  'second': False,\n",
       "  'connect': False,\n",
       "  'ceviche': False,\n",
       "  'foo': False,\n",
       "  'past': False,\n",
       "  'halibut': False,\n",
       "  'completely': False,\n",
       "  'disgust': False,\n",
       "  'ins': False,\n",
       "  'street': False,\n",
       "  'figure': False,\n",
       "  'meet': False,\n",
       "  'someday': False,\n",
       "  'nuisance': False,\n",
       "  'positive': False,\n",
       "  'disappointed': False,\n",
       "  'lifetime': False,\n",
       "  'queen': False,\n",
       "  'chose': False,\n",
       "  'plate': False,\n",
       "  'loaf': False,\n",
       "  'expand': False,\n",
       "  'red': False,\n",
       "  'blue': False,\n",
       "  'inside': False,\n",
       "  'busy': False,\n",
       "  'talk': False,\n",
       "  'girls': False,\n",
       "  'french': False,\n",
       "  'peanut': False,\n",
       "  'totally': False,\n",
       "  'fajita': False,\n",
       "  'sour': False,\n",
       "  'peach': False,\n",
       "  'skillet': False,\n",
       "  'eager': False,\n",
       "  'gnocchi': False,\n",
       "  'naan': False,\n",
       "  'vegetable': False,\n",
       "  'samosas': False,\n",
       "  'oily': False,\n",
       "  'spicy': False,\n",
       "  'season': False,\n",
       "  'vis': False,\n",
       "  'unusually': False,\n",
       "  'wide': False,\n",
       "  'traditional': False,\n",
       "  'limit': False,\n",
       "  'seek': False,\n",
       "  'flavor': False,\n",
       "  'exist': False,\n",
       "  'join': False,\n",
       "  'dcor': False,\n",
       "  'picture': False,\n",
       "  'lively': False,\n",
       "  'communal': False,\n",
       "  'rumble': False,\n",
       "  'emanate': False,\n",
       "  'encompass': False,\n",
       "  'similar': False,\n",
       "  'interesting': False,\n",
       "  'bud': False,\n",
       "  'format': False,\n",
       "  'particularly': False,\n",
       "  'eating': False,\n",
       "  'pork': False,\n",
       "  'rind': False,\n",
       "  'tough': False,\n",
       "  'surprising': False,\n",
       "  'better': False,\n",
       "  'fry': False,\n",
       "  'steak': False,\n",
       "  'chewy': False,\n",
       "  'lack': False,\n",
       "  'basic': False,\n",
       "  'raw': False,\n",
       "  'squid': False,\n",
       "  'sablefish': False,\n",
       "  'mind': False,\n",
       "  'brown': False,\n",
       "  'avocado': False,\n",
       "  'sound': False,\n",
       "  'smoked': False,\n",
       "  'rye': False,\n",
       "  'endive': False,\n",
       "  'imagine': False,\n",
       "  'strong': False,\n",
       "  'lean': False,\n",
       "  'doubt': False,\n",
       "  'spare': False,\n",
       "  'texture': False,\n",
       "  'ribs': False,\n",
       "  'note': False,\n",
       "  'intact': False,\n",
       "  'consume': False,\n",
       "  'k': False,\n",
       "  'guess': False,\n",
       "  'crave': False,\n",
       "  'green': False,\n",
       "  'startling': False,\n",
       "  'uncommon': False,\n",
       "  'gather': False,\n",
       "  'takeaway': False,\n",
       "  'tailor': False,\n",
       "  'talent': False,\n",
       "  'impressive': False,\n",
       "  'loved': False,\n",
       "  'worried': False,\n",
       "  'huevos': False,\n",
       "  'scramble': False,\n",
       "  'tofu': False,\n",
       "  'sometime': False,\n",
       "  'veg': False,\n",
       "  'meli': False,\n",
       "  'around': False,\n",
       "  'minute': False,\n",
       "  'simply': False,\n",
       "  'league': False,\n",
       "  'have': True,\n",
       "  'italian': False,\n",
       "  'luckily': False,\n",
       "  'sat': False,\n",
       "  'corner': False,\n",
       "  'sooooo': False,\n",
       "  'regret': False,\n",
       "  'ok': False,\n",
       "  'cheerful': False,\n",
       "  'ordinary': False,\n",
       "  'knowledgeable': False,\n",
       "  'draught': False,\n",
       "  'overwhelm': False,\n",
       "  'tastewise': False,\n",
       "  'pay': False,\n",
       "  'fortune': False,\n",
       "  'nt': False,\n",
       "  'responsable': False,\n",
       "  'worse': False,\n",
       "  'girlfrends': False,\n",
       "  'wan': False,\n",
       "  'alive': False,\n",
       "  'fajitas': False,\n",
       "  'pomegranate': False,\n",
       "  'rep': False,\n",
       "  'damn': False,\n",
       "  'approachable': False,\n",
       "  'foodies': False,\n",
       "  'regulars': False,\n",
       "  'creative': False,\n",
       "  'elk': False,\n",
       "  'corn': False,\n",
       "  'beef': False,\n",
       "  'sausage': False,\n",
       "  'rattlesnake': False,\n",
       "  'prepared': False,\n",
       "  'ribeye': False,\n",
       "  'freakin': False,\n",
       "  'christmas': False,\n",
       "  'private': False,\n",
       "  'unknown': False,\n",
       "  'vegetarian': False,\n",
       "  ...},\n",
       " 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dear',\n",
       " 'leave',\n",
       " 'menu',\n",
       " 'look',\n",
       " 'exceptionally',\n",
       " 'want',\n",
       " 'eat',\n",
       " 'multiple',\n",
       " 'many',\n",
       " 'consistent',\n",
       " 'overprice',\n",
       " 'cook',\n",
       " 'go',\n",
       " 'get',\n",
       " 'undercooked',\n",
       " 'actually',\n",
       " 'attempt',\n",
       " 'dessert',\n",
       " 'donuts',\n",
       " 'taste',\n",
       " 'unchanged',\n",
       " 'fryer',\n",
       " 'taste',\n",
       " 'smell',\n",
       " 'hit',\n",
       " 'table',\n",
       " 'get',\n",
       " 'pre',\n",
       " 'portion',\n",
       " 'glad',\n",
       " 'great',\n",
       " 'whiskey',\n",
       " 'get',\n",
       " 'face',\n",
       " 'get',\n",
       " 'ever',\n",
       " 'eat',\n",
       " 'longman',\n",
       " 'memorable']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "text = text_train.at[i,'review']\n",
    "cleaned = re.sub(r'[^(a-zA-Z)\\s]',' ', text)\n",
    "tokenized = word_tokenize(cleaned)\n",
    "allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "stopped = [w for w in tokenized if not w in stop_words]\n",
    "pos = nltk.pos_tag(stopped)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for token, tag in pos:\n",
    "    if tag.startswith(\"NN\"):\n",
    "        pos = 'n'\n",
    "    elif tag.startswith('VB'):\n",
    "        pos = 'v'\n",
    "    else:\n",
    "        pos = 'a'\n",
    "    token = lemmatizer.lemmatize(token, pos)\n",
    "    if tag[0] in allowed_word_types:\n",
    "        all_words.append(token.lower())\n",
    "            \n",
    "cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dear'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = lemmatizer.lemmatize(w[0],pos)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
